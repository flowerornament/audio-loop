# Milestone v1.1: Psychoacoustics

**Status:** SHIPPED 2026-01-09
**Phases:** 4
**Total Plans:** 2

## Overview

Add perceptual metrics that better capture how sounds *feel*, not just their signal properties.

## Phases

### Phase 4: Zwicker Model Integration

**Goal**: Psychoacoustic metrics via MoSQITo/Zwicker model
**Depends on**: Phase 2 (Analysis Core)
**Plans**: 2 plans

Plans:
- [x] 04-01: Create psychoacoustic.py module with MoSQITo wrapper
- [x] 04-02: Add CLI psychoacoustic support (--no-psychoacoustic flag, human interpretation)

**Details:**

Delivered:
- Loudness (sones) - Zwicker loudness via MoSQITo
- Sharpness (acum) - perception of high-frequency energy
- Roughness (asper) - perception of rapid amplitude modulation
- Integration into `analyze` output with graceful fallback
- `--no-psychoacoustic` flag for faster analysis
- Human-readable interpretation of psychoacoustic metrics

**Note:** Fluctuation strength skipped (not implemented in MoSQITo). LUFS was already present from Phase 2.

---

## Milestone Summary

**Key Decisions:**
- Use direct MoSQITo function API (loudness_zwtv, sharpness_din_from_loudness, roughness_dw) instead of Audio class
- Lazy import MoSQITo at call time for graceful fallback when not installed
- Preprocess all audio to 48kHz mono float32 before MoSQITo analysis
- Return empty dict (not None) from analyze() when MoSQITo unavailable
- Use --no-psychoacoustic (not --skip-psychoacoustic) for clearer flag naming
- Psychoacoustic runs by default - flag opts OUT not in

**Issues Resolved:**
- Fixed MoSQITo API mismatch for sharpness function (is_stationary â†’ weighting="din")

**Issues Deferred:**
- None

**Technical Debt Incurred:**
- None

---

_For current project status, see .planning/ROADMAP.md_

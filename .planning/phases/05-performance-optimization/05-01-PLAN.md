---
phase: 05-performance-optimization
plan: 01
type: execute
---

<objective>
Profile the analyze pipeline, parallelize MoSQITo metrics, and verify sub-5s full analysis.

Purpose: The psychoacoustic metrics (loudness, sharpness, roughness) currently run serially. Profiling will identify actual bottlenecks, then parallelizing independent computations should reduce analysis time.
Output: Optimized psychoacoustic.py with parallel metric computation, benchmark results proving sub-5s analysis.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-performance-optimization/05-RESEARCH.md

# Key source files:
@src/audioloop/analyze.py
@src/audioloop/psychoacoustic.py

# Prior phase context:
@.planning/phases/04-zwicker-integration/04-02-SUMMARY.md

**Tech stack available:** MoSQITo, librosa, numpy, concurrent.futures (stdlib)
**Established patterns:** Lazy import for MoSQITo, --no-psychoacoustic flag for opt-out
**Constraining decisions:**
- Phase 4: Sharpness computed from loudness output (sharpness_din_from_loudness requires N, N_spec)
- Phase 4: Default behavior runs psychoacoustic metrics (--no-psychoacoustic opts out)

**From research:**
- Profile first with cProfile before optimizing
- ProcessPoolExecutor for independent CPU-bound tasks >500ms
- Loudness and roughness are independent; sharpness depends on loudness
- Avoid pickling large arrays - pass file paths if needed (but here we already have loaded audio)
- Resample once, not per-metric
</context>

<tasks>

<task type="auto">
  <name>Task 1: Profile analyze pipeline with cProfile</name>
  <files>tests/fixtures/sine_440hz.wav (use existing test fixture)</files>
  <action>
Create a profiling script that:
1. Uses cProfile to profile analyze() on a real audio file
2. Sorts by cumulative time to find hotspots
3. Captures timing for: librosa.load, spectral features, temporal features, loudness_zwtv, roughness_dw, sharpness_din_from_loudness, librosa.resample

Run the profiler and document findings:
- Which functions take the most time?
- What percentage is MoSQITo vs librosa?
- Are the assumptions from research correct (MoSQITo dominates)?

Output profiling results to stdout for analysis. This is diagnostic - no code changes yet.
  </action>
  <verify>Profiling script runs without error and produces timing breakdown showing top 20 functions by cumulative time</verify>
  <done>Profiling results captured showing exact timing for each analysis component; bottleneck identified</done>
</task>

<task type="auto">
  <name>Task 2: Parallelize MoSQITo metrics</name>
  <files>src/audioloop/psychoacoustic.py</files>
  <action>
Modify compute_psychoacoustic() to parallelize independent metrics:

1. Keep prepare_for_mosqito() call at start (resample once)
2. Use ProcessPoolExecutor to run loudness_zwtv and roughness_dw in parallel
3. After loudness completes, compute sharpness_din_from_loudness serially (it needs N, N_spec from loudness)
4. Set max_workers=2 (only 2 parallel tasks)

Implementation notes from research:
- Create helper functions _compute_loudness and _compute_roughness that import MoSQITo inside (for subprocess pickling)
- Pass y_48k and fs as arguments (already numpy arrays, pickling is acceptable for this size)
- Use executor.submit() pattern, not executor.map()
- Wrap in try/except to gracefully fall back to serial if parallelization fails

Keep the existing error handling and logging patterns. The function signature stays the same.
  </action>
  <verify>pytest tests/ passes (all 65 tests); audioloop analyze tests/fixtures/sine_440hz.wav --format json produces valid output with psychoacoustic metrics</verify>
  <done>compute_psychoacoustic() uses ProcessPoolExecutor for loudness+roughness; sharpness computed after loudness; all tests pass</done>
</task>

<task type="auto">
  <name>Task 3: Benchmark and verify sub-5s target</name>
  <files>none (benchmarking only)</files>
  <action>
Benchmark the optimized analyze():

1. Create a longer test audio file if needed (4+ seconds to simulate real use)
2. Run analyze() multiple times (3-5 runs) with and without --no-psychoacoustic
3. Calculate average time for each mode
4. Compare to baseline (if Task 1 captured pre-optimization timing)

Document results:
- Full analysis time (with psychoacoustic)
- Fast analysis time (--no-psychoacoustic)
- Speedup factor from parallelization
- Whether sub-5s target is met

If sub-5s is NOT met, document why and what further optimization would be needed (but don't implement - that would be scope creep).
  </action>
  <verify>Benchmark runs and produces timing results</verify>
  <done>Benchmark results documented showing analysis time; sub-5s target status confirmed</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] pytest tests/ passes all 65 tests
- [ ] audioloop analyze works with psychoacoustic metrics
- [ ] audioloop analyze --no-psychoacoustic still works
- [ ] Benchmark results documented with timing data
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Profiling data captured and analyzed
- MoSQITo metrics parallelized (loudness+roughness concurrent)
- Benchmark shows analysis time (sub-5s target or documented why not)
- No regressions in test suite
</success_criteria>

<output>
After completion, create `.planning/phases/05-performance-optimization/05-01-SUMMARY.md`:

# Phase 5 Plan 1: Performance Optimization Summary

**[Substantive one-liner about optimization results]**

## Accomplishments

- [Profiling findings]
- [Parallelization implementation]
- [Benchmark results]

## Files Created/Modified

- `src/audioloop/psychoacoustic.py` - Parallel MoSQITo computation

## Decisions Made

- [Any decisions about parallelization approach]

## Profiling Results

[Before/after timing data]

## Benchmark Results

[Final timing with sub-5s status]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

Phase 5 complete, ready for Phase 6 (Spectrogram Visualization)
</output>
